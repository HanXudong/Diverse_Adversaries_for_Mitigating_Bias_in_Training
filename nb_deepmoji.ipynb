{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,argparse,time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.deep_moji import DeepMojiDataset\n",
    "from networks.deepmoji_sa import DeepMojiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.eval_metrices import group_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Parameters\n",
    "params = {'batch_size': 1024,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "# Device\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    use_fp16 = False\n",
    "    cuda = \"cuda\"\n",
    "    hidden_size = 300\n",
    "    emb_size = 2304\n",
    "    num_classes = 2\n",
    "    n_hidden = 2\n",
    "    adv = False\n",
    "    adv_level = -1\n",
    "    lr = 3e-5\n",
    "    LAMBDA = 1e-4 # adversarial \n",
    "    adv_units = 256\n",
    "    ratio = 0.8\n",
    "    dropout = 0.5\n",
    "\n",
    "data_path = #Your data path\n",
    "args = Args()\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading preprocessed deepMoji Encoded data\n",
      "Done, loaded data shapes: (99998, 2304), (99998,), (99998,)\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"\n",
    "train_data = DeepMojiDataset(args, data_path, split, ratio=args.ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading preprocessed deepMoji Encoded data\n",
      "Done, loaded data shapes: (8000, 2304), (8000,), (8000,)\n"
     ]
    }
   ],
   "source": [
    "dev_data = DeepMojiDataset(args, data_path, \"dev\", n=200000, ratio=args.ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading preprocessed deepMoji Encoded data\n",
      "Done, loaded data shapes: (7998, 2304), (7998,), (7998,)\n"
     ]
    }
   ],
   "source": [
    "test_data = DeepMojiDataset(args, data_path, \"test\", n=200000, ratio=args.ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = torch.utils.data.DataLoader(train_data, **params)\n",
    "validation_generator = torch.utils.data.DataLoader(dev_data, **params)\n",
    "test_generator = torch.utils.data.DataLoader(test_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepMojiModel(args)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "LEARNING_RATE = args.lr\n",
    "\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'max', factor = 0.5, patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, criterion, clipping_value, device, args):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(iterator):\n",
    "        \n",
    "        text = batch[0]\n",
    "        tags = batch[1].long()\n",
    "        # tags = batch[2].long() # Reverse\n",
    "        p_tags = batch[2].float()\n",
    "        # p_tags = batch[1]\n",
    "\n",
    "        text = text.to(device)\n",
    "        tags = tags.to(device)\n",
    "        p_tags = p_tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if args.Augmentation:\n",
    "            predictions = model(text, p_tags)\n",
    "        else:\n",
    "            predictions = model(text)\n",
    "        \n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                        \n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), clipping_value)\n",
    "        \n",
    "        optimizer.step()\n",
    "        # print(loss.item())\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, batch, optimizer, criterion, clipping_value, device, args):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # for batch in tqdm(iterator):\n",
    "        \n",
    "    text = batch[0]\n",
    "    tags = batch[1].long()\n",
    "    # tags = batch[2].long() # Reverse\n",
    "    p_tags = batch[2].float()\n",
    "    # p_tags = batch[1] \n",
    "    text = text.to(device)\n",
    "    tags = tags.to(device)\n",
    "    p_tags = p_tags.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if args.Augmentation:\n",
    "        predictions = model(text, p_tags)\n",
    "    else:\n",
    "        predictions = model(text)\n",
    "\n",
    "\n",
    "    loss = criterion(predictions, tags)\n",
    "\n",
    "    loss.backward() \n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), clipping_value)\n",
    "\n",
    "    optimizer.step()\n",
    "    # print(loss.item())\n",
    "    epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, iterator, criterion, device, args):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "    private_labels = []\n",
    "\n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch[0]\n",
    "\n",
    "        tags = batch[1]\n",
    "        # tags = batch[2] #Reverse\n",
    "        p_tags = batch[2]\n",
    "\n",
    "        text = text.to(device)\n",
    "        tags = tags.to(device).long()\n",
    "        p_tags = p_tags.to(device).float()\n",
    "        \n",
    "        if args.Augmentation:\n",
    "            predictions = model(text, p_tags)\n",
    "        else:\n",
    "            predictions = model(text)\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        predictions = predictions.detach().cpu()\n",
    "        tags = tags.cpu().numpy()\n",
    "\n",
    "        preds += list(torch.argmax(predictions, axis=1).numpy())\n",
    "        labels += list(tags)\n",
    "\n",
    "        private_labels += list(batch[2].cpu().numpy())\n",
    "        # private_labels += list(batch[1].cpu().numpy()) # Reverse\n",
    "\n",
    "    \n",
    "    return ((epoch_loss / len(iterator)), preds, labels, private_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 98/98 [00:01<00:00, 63.57it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 63.43it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 66.28it/s]\n",
      "  6%|▌         | 6/98 [00:00<00:01, 54.74it/s]2\n",
      "100%|██████████| 98/98 [00:01<00:00, 64.76it/s]\n",
      "  6%|▌         | 6/98 [00:00<00:01, 54.50it/s]3\n",
      "100%|██████████| 98/98 [00:01<00:00, 66.04it/s]\n",
      "  6%|▌         | 6/98 [00:00<00:01, 58.75it/s]4\n",
      "100%|██████████| 98/98 [00:01<00:00, 67.07it/s]\n",
      "  6%|▌         | 6/98 [00:00<00:01, 54.75it/s]5\n",
      "100%|██████████| 98/98 [00:01<00:00, 65.66it/s]\n",
      "  5%|▌         | 5/98 [00:00<00:01, 48.25it/s]6\n",
      "100%|██████████| 98/98 [00:01<00:00, 64.42it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 66.68it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 66.28it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 66.24it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 67.39it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "best_loss, preds, labels, p_labels = eval(model, validation_generator, criterion, device, args)\n",
    "best_acc = accuracy_score(preds, labels)\n",
    "best_epoch = -1\n",
    "for i in range(60):\n",
    "    train_epoch(model, training_generator, optimizer, criterion, 1, device, args)\n",
    "    valid_loss, preds, labels, p_labels = eval(model, validation_generator, criterion, device, args)\n",
    "    # learning rate scheduler\n",
    "    scheduler.step(valid_loss)\n",
    "    epoch_acc = accuracy_score(preds, labels)\n",
    "    if valid_loss < best_loss:\n",
    "        if i >= 2:\n",
    "            print(i)\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = i\n",
    "            torch.save(model.state_dict(), \"models\\\\deepmoji_model.pt\")\n",
    "    else:\n",
    "        if best_epoch+5<=i:\n",
    "            break\n",
    "model.load_state_dict(torch.load(\"models\\\\deepmoji_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7154288572143036"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "test_loss, preds, labels, p_labels = eval(model, test_generator, criterion, device, args)\n",
    "accuracy_score(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(preds)\n",
    "labels = np.array(labels)\n",
    "p_labels = np.array(p_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 0: 0.75575\nAccuracy 1: 0.675087543771886\nTPR 0: 0.601\nTPR 1: 0.92096048024012\nTNR 0: 0.9105\nTNR 1: 0.42921460730365185\nTPR gap: -0.31996048024012\nTNR gap: 0.4812853926963481\n"
     ]
    }
   ],
   "source": [
    "eval_metrices = group_evaluation(preds, labels, p_labels, silence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.715418771885943"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "(eval_metrices[\"Accuracy_0\"]+eval_metrices[\"Accuracy_1\"])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakage Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.eval_metrices import leakage_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dev Accuracy: 0.689625\nTest Accuracy: 0.7005501375343836\n"
     ]
    }
   ],
   "source": [
    "leakage_evaluation(model, \n",
    "                    0, \n",
    "                    training_generator,\n",
    "                    validation_generator,\n",
    "                    test_generator,\n",
    "                    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dev Accuracy: 0.839875\nTest Accuracy: 0.8475868967241811\n"
     ]
    }
   ],
   "source": [
    "leakage_evaluation(model, \n",
    "                    -1, \n",
    "                    training_generator,\n",
    "                    validation_generator,\n",
    "                    test_generator,\n",
    "                    device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('py37': conda)",
   "language": "python",
   "name": "python37764bitpy37conda9d0a1073d6454144b74835e46260853c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}